{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fix Environment"
      ],
      "metadata": {
        "id": "NFvXk6BBryRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ncBnWJ4MeEhR",
        "outputId": "31519e9b-a70c-499a-b6c4-e48b861c096b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jan 31 21:18:00 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./sample_data"
      ],
      "metadata": {
        "id": "lyFdm8FId8zF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess Data"
      ],
      "metadata": {
        "id": "ve95Ex0E7SBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "# URLs for the zip files\n",
        "links = [\n",
        "    'https://nihcc.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.gz',\n",
        "    'https://nihcc.box.com/shared/static/i28rlmbvmfjbl8p2n3ril0pptcmcu9d1.gz',\n",
        "    'https://nihcc.box.com/shared/static/f1t00wrtdk94satdfb9olcolqx20z2jp.gz',\n",
        "\t  'https://nihcc.box.com/shared/static/0aowwzs5lhjrceb3qp67ahp0rd1l1etg.gz',\n",
        "    'https://nihcc.box.com/shared/static/v5e3goj22zr6h8tzualxfsqlqaygfbsn.gz',\n",
        "  \t'https://nihcc.box.com/shared/static/asi7ikud9jwnkrnkj99jnpfkjdes7l6l.gz',\n",
        "  \t'https://nihcc.box.com/shared/static/jn1b4mw4n6lnh74ovmcjb8y48h8xj07n.gz',\n",
        "    'https://nihcc.box.com/shared/static/tvpxmn7qyrgl0w8wfh9kqfjskv6nmm1j.gz',\n",
        "    'https://nihcc.box.com/shared/static/upyy3ml7qdumlgk2rfcvlb9k6gvqq2pj.gz',\n",
        "    'https://nihcc.box.com/shared/static/l6nilvfa9cg3s28tqv1qc1olm3gnz54p.gz',\n",
        "    'https://nihcc.box.com/shared/static/hhq8fkdgvcari67vfhs7ppg2w6ni4jze.gz',\n",
        "    'https://nihcc.box.com/shared/static/ioqwiy20ihqwyr8pf4c24eazhh281pbu.gz'\n",
        "]\n",
        "\n",
        "IMAGE_DIR = \"./images\"\n",
        "DATASET_DIR = \"./dataset\"\n",
        "os.makedirs(DATASET_DIR, exist_ok=True)\n",
        "\n",
        "for index, link in enumerate(links):\n",
        "    tar = \"images_%02d.tar.gz\" % (index + 1)\n",
        "    tar_path = os.path.join(DATASET_DIR, tar)\n",
        "    urllib.request.urlretrieve(link, tar_path)\n",
        "    print(f\"Downloaded {tar}\")\n",
        "\n",
        "    with tarfile.open(tar_path, \"r\") as tar:\n",
        "        for member in tar.getmembers():\n",
        "            if member.isfile() and member.name.lower().endswith(\".png\"):\n",
        "                member.name = os.path.basename(member.name)  # remove the path\n",
        "                tar.extract(member, path=IMAGE_DIR)\n",
        "    print(f\"Extracted {tar}\")\n",
        "\n",
        "    os.remove(tar_path)\n",
        "\n",
        "print(\"Download and extraction complete\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8T6b0xsUV2MP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2fac1fe-4e6b-4f09-ac74-ca828a091b81"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded images_01.tar.gz\n",
            "Extracted <tarfile.TarFile object at 0x79093fef0c90>\n",
            "Downloaded images_02.tar.gz\n",
            "Extracted <tarfile.TarFile object at 0x79093fd24510>\n",
            "Downloaded images_03.tar.gz\n",
            "Extracted <tarfile.TarFile object at 0x79093fee61d0>\n",
            "Downloaded images_04.tar.gz\n",
            "Extracted <tarfile.TarFile object at 0x79093e6fc550>\n",
            "Downloaded images_05.tar.gz\n",
            "Extracted <tarfile.TarFile object at 0x79093fd86850>\n",
            "Downloaded images_06.tar.gz\n",
            "Extracted <tarfile.TarFile object at 0x79093ff5e610>\n",
            "Downloaded images_07.tar.gz\n",
            "Extracted <tarfile.TarFile object at 0x79093fe06710>\n",
            "Downloaded images_08.tar.gz\n",
            "Extracted <tarfile.TarFile object at 0x79093f4d15d0>\n",
            "Downloaded images_09.tar.gz\n",
            "Extracted <tarfile.TarFile object at 0x79094c753e90>\n",
            "Downloaded images_10.tar.gz\n",
            "Extracted <tarfile.TarFile object at 0x79093fe493d0>\n",
            "Downloaded images_11.tar.gz\n",
            "Extracted <tarfile.TarFile object at 0x79093fd03850>\n",
            "Downloaded images_12.tar.gz\n",
            "Extracted <tarfile.TarFile object at 0x79093f040610>\n",
            "Download and extraction complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create binary matrix CSV that maps all images with its labels\n",
        "import pandas as pd\n",
        "\n",
        "ORIGINAL_CSV = \"./dataset/Data_Entry_2017_v2020.csv\"\n",
        "BINARY_MATRIX_CSV = \"all_labels.csv\"\n",
        "\n",
        "df = pd.read_csv(ORIGINAL_CSV, usecols=[\"Image Index\", \"Finding Labels\"])\n",
        "df[\"Finding Labels\"] = df[\"Finding Labels\"].fillna(\"\")\n",
        "\n",
        "# Get all possible labels\n",
        "unique_labels_set = set()\n",
        "labels_series = df[\"Finding Labels\"].str.split(\"|\")\n",
        "for labels in labels_series:\n",
        "    for label in labels:\n",
        "        if label and label != \"No Finding\":\n",
        "            unique_labels_set.add(label)\n",
        "unique_labels = sorted(unique_labels_set)\n",
        "\n",
        "# Fill in binary matrix CSV\n",
        "for label in unique_labels:\n",
        "    df[label] = df[\"Finding Labels\"].apply(lambda x: 1 if label in x.split(\"|\") else 0)\n",
        "binary_df = df[[\"Image Index\"] + unique_labels]\n",
        "\n",
        "binary_df.to_csv(BINARY_MATRIX_CSV, index=False)"
      ],
      "metadata": {
        "id": "C_4gSjQo5jWT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split training and validation data\n",
        "TRAIN_CSV = \"train_labels.csv\"\n",
        "VAL_CSV = \"val_labels.csv\"\n",
        "\n",
        "df = pd.read_csv(BINARY_MATRIX_CSV)\n",
        "\n",
        "RANDOM_SEED = 42  # Chosen arbitrarily for reproducibility\n",
        "train_df = df.sample(frac=0.8, random_state=RANDOM_SEED)\n",
        "val_df = df.drop(train_df.index)\n",
        "\n",
        "train_df.to_csv(TRAIN_CSV, index=False)\n",
        "val_df.to_csv(VAL_CSV, index=False)"
      ],
      "metadata": {
        "id": "hwA_1PJV7QD9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the extracted images files in ./images into their respective folder\n",
        "import shutil\n",
        "\n",
        "TRAIN_DIR = \"./train\"\n",
        "VAL_DIR = \"./val\"\n",
        "\n",
        "os.makedirs(TRAIN_DIR, exist_ok=True)\n",
        "os.makedirs(VAL_DIR, exist_ok=True)\n",
        "\n",
        "for image in train_df[\"Image Index\"]:\n",
        "    src = os.path.join(IMAGE_DIR, image)\n",
        "    dst = os.path.join(TRAIN_DIR, image)\n",
        "    if os.path.exists(src):\n",
        "        shutil.move(src, dst)\n",
        "\n",
        "for image in val_df[\"Image Index\"]:\n",
        "    src = os.path.join(IMAGE_DIR, image)\n",
        "    dst = os.path.join(VAL_DIR, image)\n",
        "    if os.path.exists(src):\n",
        "        shutil.move(src, dst)"
      ],
      "metadata": {
        "id": "x-Vr-oeO8AGT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "ZMvAMlCGBkkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, models, datasets"
      ],
      "metadata": {
        "id": "QY96GOewllh1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 12\n",
        "batch_size = 32\n",
        "learning_rate = 1e-4\n",
        "device = torch.device(\"cuda\") # if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "MiSzmJ4-lzm8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import PIL\n",
        "\n",
        "class ChestXrayDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, images_dir, csv_file, transform=None):\n",
        "        self.images_dir = images_dir\n",
        "        self.annotations = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "        self.image_names = self.annotations.iloc[:, 0].values\n",
        "        self.labels = self.annotations.iloc[:, 1:].values.astype(float)\n",
        "        self.num_classes = self.labels.shape[1]\n",
        "\n",
        "        self.class_labels = list(self.annotations.columns)[1:]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.images_dir, self.image_names[idx])\n",
        "        image = PIL.Image.open(img_name).convert('RGB')\n",
        "        labels = torch.FloatTensor(self.labels[idx])\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, labels"
      ],
      "metadata": {
        "id": "IGaENmovlytI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data transformations\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "ualDVM64l4bZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Datasets and Dataloaders\n",
        "train_dataset = ChestXrayDataset(\n",
        "    images_dir=TRAIN_DIR,\n",
        "    csv_file=TRAIN_CSV,\n",
        "    transform=transform\n",
        ")\n",
        "val_dataset = ChestXrayDataset(\n",
        "    images_dir=VAL_DIR,\n",
        "    csv_file=VAL_CSV,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "TgwY6Lg1Z8iZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "num_labels = train_dataset.num_classes\n",
        "class_labels = train_loader.dataset.class_labels\n",
        "print(f\"Number of labels: {num_labels}\")\n",
        "print(f\"Labels: {class_labels}\")\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Freeze all layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(model.fc.in_features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(256, 14)\n",
        ")\n",
        "\n",
        "# Unfreeze fc layers\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGOhkPkldKNj",
        "outputId": "7ab9e4e5-5e8d-46f4-c932-945aabbae499"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of labels: 14\n",
            "Labels: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 64.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "7oMaPpdedW8D"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "patience = 3\n",
        "counter = 0\n",
        "best_val_loss = float(\"inf\")\n",
        "\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    val_loss = val_running_loss / len(val_loader.dataset)\n",
        "\n",
        "    # Early stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
        "            break\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Training complete\")\n",
        "print(f\"Training time took: {end_time - start_time:.4f} seconds\")"
      ],
      "metadata": {
        "id": "v7jVTvInqKiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "import datetime\n",
        "\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
        "model_filename = f\"{timestamp}_resnet50model.pth\"\n",
        "\n",
        "torch.save(model.state_dict(), model_filename)\n",
        "print(\"Saved model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tmsfCuSrVHJ",
        "outputId": "76efa740-011d-492e-d903-1c1e78e25b26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_path, num_labels, device):\n",
        "    model = models.resnet50(pretrained=False)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_labels)\n",
        "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
        "    model = model.to(device)\n",
        "    return model\n",
        "\n",
        "def predict(model, dataloader, device, class_labels, threshold=0.3):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            preds = torch.sigmoid(outputs) > threshold\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Print the first 5 predictions with class labels\n",
        "    for i in range(5):\n",
        "        predicted_labels = [class_labels[j] for j in range(num_labels) if all_preds[i][j]]\n",
        "        true_labels = [class_labels[j] for j in range(num_labels) if all_labels[i][j]]\n",
        "        print(f\"Image {i+1}:\")\n",
        "        print(f\"  Predicted Labels: {predicted_labels}\")\n",
        "        print(f\"  True Labels: {true_labels}\")\n",
        "\n",
        "model = load_model(\"./resnet_model.pth\", num_labels, device)\n",
        "predict(model, train_loader, device, class_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1YVluJUuHcS",
        "outputId": "87d877c3-bf3c-49df-bbb8-4022e41a8979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 1:\n",
            "  Predicted Labels: ['Mass', 'Nodule', 'Pleural_Thickening']\n",
            "  True Labels: ['Mass', 'Nodule', 'Pleural_Thickening']\n",
            "Image 2:\n",
            "  Predicted Labels: []\n",
            "  True Labels: []\n",
            "Image 3:\n",
            "  Predicted Labels: ['Fibrosis', 'Pleural_Thickening']\n",
            "  True Labels: ['Fibrosis', 'Pleural_Thickening']\n",
            "Image 4:\n",
            "  Predicted Labels: []\n",
            "  True Labels: []\n",
            "Image 5:\n",
            "  Predicted Labels: ['Atelectasis', 'Infiltration']\n",
            "  True Labels: ['Atelectasis', 'Infiltration']\n"
          ]
        }
      ]
    }
  ]
}